#SpikeFunction_Classical_RELU : 329.728, 291.934, 286.239, 284.302, 282.698, 281.585, 280.547, 279.528, 278.571, 277.948, 277.537, 277.108, 276.576, 276.031, 275.388, 274.871, 274.615, 274.167, 273.856, 273.742
#SpikeFunction_Leaky_RELU : 319.772, 223.502, 195.678, 182.265, 173.437, 166.852, 161.287, 157.319, 153.999, 151.130, 149.593, 147.591, 145.535, 144.609, 142.912, 142.218, 140.789, 140.001, 139.382, 140.735
#SpikeFunction_Abs_RELU : 3668281.976, 40119.797, 20847.914, 14233.874, 10871.039, 8813.481, 7500.289, 6557.241, 5871.511, 5328.475, 4920.224, 4571.677, 4288.173, 4059.487, 3865.771, 3703.516, 3556.629, 3416.941, 3297.287, 3192.597
#SpikeFunction_Sigmoid : 891.203, 828.893, 596.069, 189.733, 147.170, 130.478, 118.558, 109.295, 101.959, 96.066, 91.100, 87.151, 83.748, 80.378, 77.904, 75.744, 73.625, 71.727, 70.318, 68.809
#SpikeFunction_Triangular : 926.873, 907.746, 929.722, 952.984, 973.329, 985.180, 994.232, 999.763, 1006.568, 1012.012, 1017.807, 1021.983, 1029.860, 1037.166, 1042.510, 1047.766, 1052.846, 1055.680, 1058.149, 1061.835
#SpikeFunction_Gaussian : 600.424, 233.173, 180.391, 157.995, 146.092, 138.869, 136.420, 132.812, 127.128, 124.786, 119.202, 119.037, 117.030, 111.415, 109.747, 107.547, 106.260, 106.711, 105.340, 104.597

import matplotlib.pyplot as plt

# Données de loss pour chaque fonction d'activation
# SANS LE DT/TAU_V
loss_classical_relu = [329.728, 291.934, 286.239, 284.302, 282.698, 281.585, 280.547, 279.528, 278.571, 277.948, 277.537, 277.108, 276.576, 276.031, 275.388, 274.871, 274.615, 274.167, 273.856, 273.742]
loss_leaky_relu = [319.772, 223.502, 195.678, 182.265, 173.437, 166.852, 161.287, 157.319, 153.999, 151.130, 149.593, 147.591, 145.535, 144.609, 142.912, 142.218, 140.789, 140.001, 139.382, 140.735]
loss_abs_relu = [3668281.976, 40119.797, 20847.914, 14233.874, 10871.039, 8813.481, 7500.289, 6557.241, 5871.511, 5328.475, 4920.224, 4571.677, 4288.173, 4059.487, 3865.771, 3703.516, 3556.629, 3416.941, 3297.287, 3192.597]
loss_sigmoid = [891.203, 828.893, 596.069, 189.733, 147.170, 130.478, 118.558, 109.295, 101.959, 96.066, 91.100, 87.151, 83.748, 80.378, 77.904, 75.744, 73.625, 71.727, 70.318, 68.809]
loss_triangular = [926.873, 907.746, 929.722, 952.984, 973.329, 985.180, 994.232, 999.763, 1006.568, 1012.012, 1017.807, 1021.983, 1029.860, 1037.166, 1042.510, 1047.766, 1052.846, 1055.680, 1058.149, 1061.835]
loss_gaussian = [600.424, 233.173, 180.391, 157.995, 146.092, 138.869, 136.420, 132.812, 127.128, 124.786, 119.202, 119.037, 117.030, 111.415, 109.747, 107.547, 106.260, 106.711, 105.340, 104.597]

# Tracer le graphique
plt.figure(figsize=(10, 6))
plt.plot(loss_classical_relu, label='SpikeFunction_Classical_RELU')
plt.plot(loss_leaky_relu, label='SpikeFunction_Leaky_RELU')
plt.plot(loss_abs_relu, label='SpikeFunction_Abs_RELU')
plt.plot(loss_sigmoid, label='SpikeFunction_Sigmoid')
plt.plot(loss_triangular, label='SpikeFunction_Triangular')
plt.plot(loss_gaussian, label='SpikeFunction_Gaussian')

# Ajouter des titres et des légendes
plt.title('Évolution du Loss pour différentes fonctions d\'activation')
plt.xlabel('Époque')
plt.ylabel('Loss')
plt.yscale('log')
plt.legend()

# Afficher le graphique
#plt.show()


# AVEC LE DT/TAU_V
#SpikeFunction_Classical_RELU , W1 W2 CENTRÉ A 1  : 2114.054, 772.994, 766.408, 757.060, 743.999, 724.217, 695.609, 659.926, 623.320, 589.953, 560.016, 532.694, 507.517, 484.674, 465.058, 448.675, 434.819, 423.322, 413.314, 404.728

#SpikeFunction_Classical_RELU : 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000
#SpikeFunction_Leaky_RELU : 808.991, 550.051, 368.908, 313.473, 290.681, 276.873, 266.416, 257.095, 248.118, 239.765, 231.882, 224.524, 218.007, 212.650, 207.436, 201.804, 196.989, 192.583, 188.027, 183.743
#SpikeFunction_Abs_RELU : 1595.861, 784.307, 814.510, 763.077, 745.070, 717.860, 695.117, 680.703, 671.684, 664.022, 655.658, 648.442, 642.663, 637.108, 632.217, 626.883, 623.256, 619.869, 616.751, 614.180
#SpikeFunction_Sigmoid : 494.872, 411.637, 373.410, 336.759, 306.259, 283.273, 265.894, 252.413, 241.885, 233.203, 226.023, 220.002, 214.773, 210.270, 206.251, 202.735, 199.565, 196.655, 194.014, 191.560
#SpikeFunction_Triangular : 1088.317, 981.029, 953.323, 944.013, 939.024, 936.853, 936.187, 935.114, 934.668, 933.492, 933.951, 932.649, 931.110, 931.724, 931.536, 928.899, 926.419, 924.752, 924.319, 924.375
#SpikeFunction_Gaussian : 1034.577, 701.185, 392.080, 232.452, 161.878, 146.104, 135.808, 127.524, 120.872, 115.206, 109.971, 105.517, 101.511, 98.090, 94.982, 92.286, 89.794, 87.567, 85.526, 83.603

#SpikeFunction_Gaussian avec fct para: 1034.411, 720.980, 599.317, 395.483, 293.762, 243.226, 232.055, 223.866, 168.737, 126.787, 118.805, 113.072, 108.011, 104.008, 100.401, 97.347, 94.424, 91.814, 89.433, 87.514

loss_classical_relu_2 = [1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000, 1090.000]
loss_leaky_relu_2 = [808.991, 550.051, 368.908, 313.473, 290.681, 276.873, 266.416, 257.095, 248.118, 239.765, 231.882, 224.524, 218.007, 212.650, 207.436, 201.804, 196.989, 192.583, 188.027, 183.743]
loss_abs_relu_2 = [1595.861, 784.307, 814.510, 763.077, 745.070, 717.860, 695.117, 680.703, 671.684, 664.022, 655.658, 648.442, 642.663, 637.108, 632.217, 626.883, 623.256, 619.869, 616.751, 614.180]
loss_sigmoid_2 = [494.872, 411.637, 373.410, 336.759, 306.259, 283.273, 265.894, 252.413, 241.885, 233.203, 226.023, 220.002, 214.773, 210.270, 206.251, 202.735, 199.565, 196.655, 194.014, 191.560]
loss_triangular_2 = [1088.317, 981.029, 953.323, 944.013, 939.024, 936.853, 936.187, 935.114, 934.668, 933.492, 933.951, 932.649, 931.110, 931.724, 931.536, 928.899, 926.419, 924.752, 924.319, 924.375]
loss_gaussian_2 = [1034.577, 701.185, 392.080, 232.452, 161.878, 146.104, 135.808, 127.524, 120.872, 115.206, 109.971, 105.517, 101.511, 98.090, 94.982, 92.286, 89.794, 87.567, 85.526, 83.603]
# Tracer le deuxième graphique (AVEC LE DT/TAU_V)
plt.figure(figsize=(10, 6))
plt.plot(loss_classical_relu_2, label='SpikeFunction_Classical_RELU')
plt.plot(loss_leaky_relu_2, label='SpikeFunction_Leaky_RELU')
plt.plot(loss_abs_relu_2, label='SpikeFunction_Abs_RELU')
plt.plot(loss_sigmoid_2, label='SpikeFunction_Sigmoid')
plt.plot(loss_triangular_2, label='SpikeFunction_Triangular')
plt.plot(loss_gaussian_2, label='SpikeFunction_Gaussian')

# Ajouter des titres et des légendes
plt.title('Évolution du Loss pour différentes fonctions d\'activation')
plt.xlabel('Époque')
plt.ylabel('Loss')
plt.yscale('log')
plt.legend()

# Afficher le deuxième graphique
plt.show()


# AVEC 2 couches :
#SpikeFunction_Leaky_RELU  : 813.576, 743.385, 699.535, 568.494, 370.584, 290.379, 258.991, 240.160, 223.970, 211.079, 201.328, 193.490, 186.750, 180.710, 175.592, 171.308, 167.763, 164.516, 161.224, 157.985
