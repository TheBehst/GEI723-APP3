{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWI1p59MgcLE"
      },
      "source": [
        "Introduction to PyTorch on Google Colaboratory  \n",
        "===============================================\n",
        "\n",
        "Copyright (c) 2019-2024, NECOTIS  (All rights reserved.)\n",
        "\n",
        "Authors: Ismael Balafrej, Ahmad El Ferdaoussi, Alexis MÃ©lotL, Arnaud Yarga\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdRSYrrD-M2_"
      },
      "source": [
        "Google Colab\n",
        "============\n",
        "\n",
        "As defined by Google: Colaboratory is a free Jupyter notebook environment that requires no setup and runs entirely in the cloud. With Colaboratory you can write and execute code, save and share your analyses, and access powerful computing resources, all for free from your browser.\n",
        "\n",
        "Your jupyter notebooks can be uploaded directly using the interface. It runs on the cloud and it's entirely free (or at least for the moment, so let's get the most out of it!). All you need is a Google account (typically Gmail) since your notebooks are saved directly in your Google Drive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwheSENo_gSZ"
      },
      "outputs": [],
      "source": [
        "# Most python packages for ML and data processing in general are pre-installed\n",
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H8wW4T2AroM",
        "outputId": "ac4aa132-c879-47dd-f008-1c4aef5c2779"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       1.3Gi       5.9Gi       1.0Mi       5.5Gi        11Gi\n",
            "Swap:             0B          0B          0B\n",
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   33G   81G  29% /\n"
          ]
        }
      ],
      "source": [
        "# In the upper right corner, you can see the physical limits in disk space and ram, normally it's big enough for most application\n",
        "!free -h\n",
        "!df -h /"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75R5lJqAEJ88",
        "outputId": "596cd880-c2bb-42f0-bc08-dfdc4999aa22"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 11 22:10:41 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# Most importantly, you have access to a fairly new GPU for high parallelisation processing\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-eQTD2MGCeP"
      },
      "source": [
        "Keep it mind that Colab is free to use for research purposes. You have up to 12h of continuous usage so this should be more than good enough for this problem.\n",
        "You **cannot** use it for cryptocurrency mining, prime factorization, or other misuse."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tL-qRuuGlxA"
      },
      "source": [
        "PyTorch\n",
        "=======\n",
        "As defined by Wikipedia: PyTorch is an open source machine learning library based on the Torch library, used for applications such as computer vision and natural language processing. It is primarily developed by Facebook's AI Research Group. It is free and open-source software released under the Modified BSD license.\n",
        "\n",
        "Although the official name is PyTorch, the package is referred to as torch. You can install it on your machine with a `pip install torch` or `conda install -c pytorch pytorch`.\n",
        "\n",
        "You can find PyTorch tutorials at https://pytorch.org/tutorials/ and the documentation at https://pytorch.org/docs/stable/index.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Fm6a2pRHcnI"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0) # As always, we can set the seed for reproductibility\n",
        "np.random.seed(0)\n",
        "\n",
        "# As it's core, pytorch is very similar to numpy. The major distinction is that you can select a device and transfer between devices.\n",
        "\n",
        "# Here we select the device based on what is available. If we have a gpu access, the device will be the GPU, otherwise, we'll run the code on CPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "# Pytorch is fairly agnostic on whether you use a GPU or a CPU when you write python code. The only thing you have to keep in mind\n",
        "# is to keep your operation on the same device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXzhXtrZIVC8"
      },
      "outputs": [],
      "source": [
        "# Another small distinction is that in numpy, the main data structure is called an array while in pytorch it's called a tensor\n",
        "X_np = np.ones((100, 100))\n",
        "X_torch = torch.ones((100, 100), device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dupz26bSIuqS",
        "outputId": "16d0e6bb-d441-4f62-9288-e7c645cccbf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 100)\n",
            "torch.Size([100, 100])\n",
            "2\n",
            "2\n"
          ]
        }
      ],
      "source": [
        "# While the API is mostly the same, the underlying types are not always identical\n",
        "# But for most cases, it doesn't matter\n",
        "print(X_np.shape)\n",
        "print(X_torch.shape)\n",
        "print(X_np.ndim)\n",
        "print(X_torch.ndim)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--kpYIMfI9qJ",
        "outputId": "295b5ce3-0ab2-4955-c7ad-8cef32f71fb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# You can also convert seamless between numpy arrays and pytorch tensors if need be\n",
        "# Although, since numpy is CPU only, you have to transfer the memory to the RAM first\n",
        "X_torch_to_numpy = X_torch.cpu().numpy()\n",
        "np.all(X_np == X_torch_to_numpy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfOU840jJrTR",
        "outputId": "517283b4-8911-4391-b001-0d10f8a82ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 100)\n"
          ]
        }
      ],
      "source": [
        "# In some cases, when doing gradient based methods you even have to \"detach\"\n",
        "# This is because pytorch, like tensorflow, can automatically compute the gradient for you\n",
        "# You can specify this at variable initialization\n",
        "X_torch = torch.ones((100, 100), device=device, requires_grad=True)\n",
        "print(X_torch.detach().cpu().numpy().shape) # Here we need to detach the tensor from the automatic gradient calculations in order to convert it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGKgVRTWLUOC"
      },
      "outputs": [],
      "source": [
        "# That's the reverse operation, so from numpy to pytorch\n",
        "# By default, the tensor will be converted to the CPU device\n",
        "# But since we are using a GPU here, the \"to\" method can\n",
        "# transfer the memory to the GPU\n",
        "X_np = np.random.random((1000, 1000))\n",
        "X_torch = torch.from_numpy(X_np).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXZgUmH6MAgz"
      },
      "outputs": [],
      "source": [
        "# More examples of the similarities between numpy and pytorch\n",
        "\n",
        "X_torch[0:100] *= 5\n",
        "X_np[0:100] *= 5\n",
        "\n",
        "X_torch = X_torch.T\n",
        "X_np = X_np.T\n",
        "\n",
        "amax_torch = torch.argmax(X_torch, axis=0)\n",
        "amax_np = np.argmax(X_np, axis=0)\n",
        "assert(np.all(amax_torch.cpu().numpy() == amax_np))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjPMeKZ4VZdP"
      },
      "source": [
        "As mentioned before, pytorch can be GPU accelerated. To see why this is useful, we can do a simple operation that is highly parallelizable like a matrix multiplication two hunded times (And we normalize to not overflow):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDiMPixPQ5xa",
        "outputId": "75d42aed-3d20-452d-8cba-3dedca2a3732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution took 0.189 seconds\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "for _ in range(200):\n",
        "    X_torch = torch.matmul(X_torch, X_torch)\n",
        "    X_torch /= torch.max(X_torch)\n",
        "\n",
        "print(\"Execution took %.3f seconds\" % (time.time() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R0t2IKIVTNE0",
        "outputId": "eb793677-48fb-4fe7-fd78-4b9647f4d5d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Execution took 11.814 seconds\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "\n",
        "for _ in range(200):\n",
        "    X_np = np.matmul(X_np, X_np)\n",
        "    X_np /= np.max(X_np)\n",
        "\n",
        "print(\"Execution took %.3f seconds\" % (time.time() - start))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WDRwEuqbRoX"
      },
      "source": [
        "Let's now explore a little bit more the autograd features of pytorch, which numpy doesn't have"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEWc7UcTbZs_"
      },
      "outputs": [],
      "source": [
        "# Let's create a toy dataset of two overlaping normal random points\n",
        "N = 500 # number of points per class\n",
        "X_1 = torch.distributions.normal.Normal(1, 1.).sample((N,)).float().to(device)\n",
        "X_2 = torch.distributions.normal.Normal(3, 1).sample((N,)).float().to(device)\n",
        "y_1 = torch.zeros(N, device=device) # Label 1 = 0\n",
        "y_2 = torch.ones(N, device=device) # Label 2 = 1\n",
        "X = torch.cat([X_1, X_2], dim=0) # Concatenate the data\n",
        "y = torch.cat([y_1, y_2], dim=0) # And the labels\n",
        "random_indexes = torch.randperm(2*N) # Randomly permute the array\n",
        "X = X[random_indexes].view(-1, 1) # View here will convert a (N,) shaped array to a (N, 1) shaped matrix\n",
        "y = y[random_indexes].view(-1, 1)\n",
        "\n",
        "# Transform the label into one-hot encoding, 0 => [1, 0] and 1 => [0, 1]\n",
        "oh_y = torch.zeros(y.shape[0], 2, device=device)\n",
        "oh_y = oh_y.scatter(1, y.long(), 1);\n",
        "\n",
        "# Normalize the input\n",
        "X = (X - torch.mean(X)) / torch.std(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 172
        },
        "id": "XGfSF7eyNo6R",
        "outputId": "b2b7d088-6ac1-48ab-8667-8c064448de2b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Here is what is looks like\n",
        "plt.figure(figsize=(15, 2))\n",
        "X_1_np = X_1.cpu().numpy()\n",
        "X_2_np = X_2.cpu().numpy()\n",
        "plt.plot(X_1_np, np.ones_like(X_1_np), 'x', color='blue', alpha=0.5);\n",
        "plt.plot(X_2_np, np.ones_like(X_2_np), '+', color='red', alpha=0.5);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dh0Y-9uSb9WT"
      },
      "outputs": [],
      "source": [
        "# Let's create a weight tensor, as we would typically do in a formal neural network\n",
        "W1 = torch.rand(1, 10, dtype=torch.float32, device=device)\n",
        "W1 = (2.*W1 - 1.) # Uniform weights between -1 and 1\n",
        "W1 = W1.requires_grad_() # Same as if we would have initialized the variable with requires_grad=True as argument\n",
        "\n",
        "W2 = torch.rand(10, 2, dtype=torch.float32, device=device)\n",
        "W2 = (2.*W2 - 1.)\n",
        "W2 = W2.requires_grad_()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzU9DDaRcp6x"
      },
      "outputs": [],
      "source": [
        "# Feed forward part\n",
        "def sigmoid_activation_function(inp):\n",
        "    # You can add any arbitrary python functions and call them whenever\n",
        "    # Pytorch autograd will still be able to compute the gradient\n",
        "    # Here is an illustration of the sigmoid function\n",
        "    # But normally, you'd use torch.nn.Sigmoid() which is faster\n",
        "    return 1 / (1 + torch.exp(-inp))\n",
        "\n",
        "hidden_output = sigmoid_activation_function(torch.matmul(X, W1))\n",
        "output = sigmoid_activation_function(torch.matmul(hidden_output, W2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRMLbyGWnyte",
        "outputId": "7149e001-6433-43ae-ab2e-0c3c2539c252"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre training accuracy : 50.00 %\n"
          ]
        }
      ],
      "source": [
        "accuracy = torch.sum(torch.argmax(output, dim=1) == y.view(-1,)).float() / y.shape[0] * 100.\n",
        "print(\"Pre training accuracy : %.2f %%\" % accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Au-yfjDVTTST",
        "outputId": "d39fe26d-329e-4ba0-c0ab-0f74247a750a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.6400, 0.4170], device='cuda:0', grad_fn=<MeanBackward1>),\n",
              " tensor([0.0403, 0.0216], device='cuda:0', grad_fn=<StdBackward0>))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Near 50% ! That may seem good, but keep in mind that for a two class problem,\n",
        "# this is almost equivalent to a random classification\n",
        "# We can look at the output tensor's statistics to understand why:\n",
        "torch.mean(output, dim=0), torch.std(output, dim=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sw1YzlTCogWE",
        "outputId": "a907a003-343f-4f66-ce5f-e77929ca3675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss iteration 1 : 0.2430\n",
            "Loss iteration 101 : 0.1170\n",
            "Loss iteration 201 : 0.1170\n",
            "Loss iteration 301 : 0.1169\n",
            "Loss iteration 401 : 0.1169\n",
            "Loss iteration 501 : 0.1169\n",
            "Loss iteration 601 : 0.1169\n",
            "Loss iteration 701 : 0.1169\n",
            "Loss iteration 801 : 0.1169\n",
            "Loss iteration 901 : 0.1169\n",
            "Loss iteration 1001 : 0.1169\n"
          ]
        }
      ],
      "source": [
        "# Let's create a standard SGD in order to train these weights\n",
        "optimizer = torch.optim.SGD((W1, W2,), lr=5e-1, momentum=0.9)\n",
        "\n",
        "# And we'll iterate over some epochs\n",
        "for i in range(1001):\n",
        "    optimizer.zero_grad() # Reset the gradient in pytorch\n",
        "\n",
        "    # We do forward propagation once again\n",
        "    hidden_output = sigmoid_activation_function(torch.matmul(X, W1))\n",
        "    output = sigmoid_activation_function(torch.matmul(hidden_output, W2))\n",
        "\n",
        "    # We use the mean squared error as a loss function, we could also use torch.nn.MSELoss\n",
        "    loss = torch.mean((oh_y - output) ** 2)\n",
        "\n",
        "    loss.backward() # Compute the local loss for each layers\n",
        "    optimizer.step() # Do a step of SGD\n",
        "    if i % 100 == 0:\n",
        "        print(\"Loss iteration %i : %.4f\" % (i+1, loss.detach().cpu().numpy()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZLba_wf4daG",
        "outputId": "ae7757da-ab47-428c-ef25-6175c1f21fc5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Post training accuracy : 83.60 %\n"
          ]
        }
      ],
      "source": [
        "hidden_output = sigmoid_activation_function(torch.matmul(X, W1))\n",
        "output = sigmoid_activation_function(torch.matmul(hidden_output, W2))\n",
        "accuracy = torch.sum(torch.argmax(output, dim=1) == y.view(-1,)).float() / y.shape[0] * 100.\n",
        "print(\"Post training accuracy : %.2f %%\" % accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNkP--jlpGnQ"
      },
      "source": [
        "You can define your own gradients too, say you have a non differentiable function for example\n",
        "\n",
        "Here is a good example of RELU, taken from [here](https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma362hO_2zyE"
      },
      "outputs": [],
      "source": [
        "class MyReLU(torch.autograd.Function):\n",
        "    \"\"\"\n",
        "    We can implement our own custom autograd Functions by subclassing\n",
        "    torch.autograd.Function and implementing the forward and backward passes\n",
        "    which operate on Tensors.\n",
        "    \"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        \"\"\"\n",
        "        In the forward pass we receive a Tensor containing the input and return\n",
        "        a Tensor containing the output. ctx is a context object that can be used\n",
        "        to stash information for backward computation. You can cache arbitrary\n",
        "        objects for use in the backward pass using the ctx.save_for_backward method.\n",
        "        \"\"\"\n",
        "        ctx.save_for_backward(input)\n",
        "        return input.clamp(min=0)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        \"\"\"\n",
        "        In the backward pass we receive a Tensor containing the gradient of the loss\n",
        "        with respect to the output, and we need to compute the gradient of the loss\n",
        "        with respect to the input.\n",
        "        \"\"\"\n",
        "        input, = ctx.saved_tensors\n",
        "        grad_input = grad_output.clone()\n",
        "        grad_input[input < 0] = 0\n",
        "        return grad_input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nOsu97DppMpf"
      },
      "source": [
        "Let's re-create the weights so they aren't trained"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyMDgDgOawEO"
      },
      "outputs": [],
      "source": [
        "W1 = torch.rand(1, 6, dtype=torch.float32, device=device)\n",
        "W1 = (2.*W1 - 1.)\n",
        "W1 = W1.requires_grad_()\n",
        "\n",
        "W2 = torch.rand(6, 4, dtype=torch.float32, device=device)\n",
        "W2 = (2.*W2 - 1.)\n",
        "W2 = W2.requires_grad_()\n",
        "\n",
        "W3 = torch.rand(4, 2, dtype=torch.float32, device=device)\n",
        "W3 = (2.*W3 - 1.)\n",
        "W3 = W3.requires_grad_()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxhXaYz_pPCS"
      },
      "source": [
        "With our custom activation function, let's create our network.\n",
        "Here we use the Mean Square Error (MSE) loss and the Adam optimizer algorithm from PyTorch.\n",
        "\n",
        "Adam optimizer is kind of like the Stochastic Gradient Descent (SGD) algorithm but wiht an adaptive learning rate and more features making it more computationally efficient and give overall better performances than SGD.\n",
        "\n",
        "More infos can be found [here](https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEWyxqz2j7H0",
        "outputId": "d4c19c2f-ec6c-46ef-ebdc-8835fa68da5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss iteration 200 : 0.184587\n",
            "Loss iteration 400 : 0.183744\n",
            "Loss iteration 600 : 0.183709\n",
            "Loss iteration 800 : 0.183708\n",
            "Loss iteration 1000 : 0.183708\n",
            "Loss iteration 1200 : 0.183708\n",
            "Loss iteration 1400 : 0.183708\n",
            "Loss iteration 1600 : 0.183708\n",
            "Loss iteration 1800 : 0.183708\n",
            "Post training accuracy with ReLU : 83.60 %\n"
          ]
        }
      ],
      "source": [
        "hidden_activation_fnct = MyReLU.apply\n",
        "loss_fnct = torch.nn.MSELoss()\n",
        "optimizer = torch.optim.Adam((W1, W2, W3), lr = 0.003)\n",
        "\n",
        "for i in range(1,2000):\n",
        "    optimizer.zero_grad() # Reset the gradient in pytorch\n",
        "\n",
        "    # We do forward propagation once again\n",
        "    # With our custom ReLU for the hidden layers\n",
        "    hidden_output_1 = hidden_activation_fnct(torch.matmul(X, W1))\n",
        "    hidden_output_2 = hidden_activation_fnct(torch.matmul(hidden_output_1, W2))\n",
        "    output = sigmoid_activation_function(torch.matmul(hidden_output_2, W3))\n",
        "    loss = loss_fnct(output, oh_y)\n",
        "\n",
        "    loss.backward() # Compute the local loss for each layers\n",
        "    optimizer.step() # Do a step of Adam\n",
        "    if i % 200 == 0:\n",
        "        print(\"Loss iteration %i : %.6f\" % (i, loss.detach().cpu().numpy()))\n",
        "\n",
        "hidden_output_1 = hidden_activation_fnct(torch.matmul(X, W1))\n",
        "hidden_output_2 = hidden_activation_fnct(torch.matmul(hidden_output_1, W2))\n",
        "output = sigmoid_activation_function(torch.matmul(hidden_output_2, W3))\n",
        "accuracy = torch.sum(torch.argmax(output, dim=1) == y.view(-1,)).float() / y.shape[0] * 100.\n",
        "print(\"Post training accuracy with ReLU : %.2f %%\" % accuracy)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}