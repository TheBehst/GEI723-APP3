{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWTf7H60Z0i_"
   },
   "source": [
    "# Rétropropagation de l'erreur dans les réseaux de neurones à décharges\n",
    "### GEI723, Automne 2024\n",
    "Ce notebook présente comment l'algorithme de la descente du gradient peut être adapté pour la rétropropagation de l'erreur dans les réseaux de neurones à décharges avec des fonctions d'activation non dérivables.\n",
    "\n",
    "Ce notebook est utilisé dans le cadre du cours GEI723 (Neuro-Computationnel).\n",
    "\n",
    "- **Encodage de l'entrée** : Les entrées sont encodées sous forme de trains de spikes.\n",
    "- **Structure du réseau** : Réseau de neurones à décharges avec plusieurs couches, utilisant différentes fonctions d'activation\n",
    "- **Études menées** : \n",
    "  - Impact des fonctions d'activation et des dérivées sur la performance.\n",
    "  - Analyse des méta-paramètres (nombre de couches, taux d'apprentissage, taille des lots).\n",
    "  - Comparaison entre réseaux avec et sans apprentissage sur certaines couches.\n",
    "- **Objectif du code** : Optimisation et analyse de la rétropropagation de l'erreur des réseaux de neurones à décharges.\n",
    "\n",
    "**Auteurs :**\n",
    "Clémence Lamballe\n",
    "Behrouz Nik-Nejad-Kazem-Pour\n",
    "Jean-Sébastien Giroux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce notebook a été inspiré du notebook créé par Ismaël Balafrej, Ph.D. avec Jean Rouat, Ph.D., ing., professeur et adapté par Ahmad El Ferdaoussi, Ph.D. et Arnaud Yarga, étud. Ph.D, dont le copyright et les auteurs sont:\n",
    "\n",
    "Copyright (c) 2019-2024, Université de Sherbrooke, groupe de recherche NECOTIS. Tous droits réservés.  \n",
    "Auteurs: Ismael Balafrej, Jean Rouat, adapté par Ahmad El Ferdaoussi et Arnaud Yarga\n",
    "\n",
    "\n",
    "Ce travail a lui même été adapté et inspiré des articles suivants:\n",
    "1. Surrogate Gradient Learning in Spiking Neural Networks by Zenke & Ganguli (2018) https://arxiv.org/pdf/1901.09948.pdf\n",
    "2. SLAYER: Spike Layer Error Reassignment in Time (2018) https://arxiv.org/pdf/1810.08646.pdf\n",
    "3. Biologically inspired alternatives to backpropagation through time for learning in recurrent neural nets (2019) https://arxiv.org/pdf/1901.09049.pdf\n",
    "\n",
    "\n",
    "Dans cet exemple de code la gestion du potentiel et de l'intensité du neurone est placé dans la gestion des couches.\n",
    "Vous pouvez décider de le faire autrement, par exemple dans la phase de propagation avant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpKksf2Ik4ga"
   },
   "source": [
    "# Packages et imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IJGOX5B8F7ic"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: quantities in c:\\users\\cllam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.16.1)\n",
      "Requirement already satisfied: sparse in c:\\users\\cllam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.15.4)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\cllam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from quantities) (2.0.2)\n",
      "Requirement already satisfied: scipy>=0.19 in c:\\users\\cllam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sparse) (1.14.1)\n",
      "Requirement already satisfied: numba>=0.49 in c:\\users\\cllam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sparse) (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\cllam\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from numba>=0.49->sparse) (0.43.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install quantities sparse\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, model_selection, utils\n",
    "import torch\n",
    "import quantities as units\n",
    "from sparse import COO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BspwdQSOk8U-"
   },
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ngz0VkgVmJB6"
   },
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Use the GPU unless there is none available.\n",
    "# If you don't have a CUDA enabled GPU, I recommned using Google Colab,\n",
    "# available at https://colab.research.google.com. Create a new notebook\n",
    "# and then go to Runtime -> Change runtime type -> Hardware accelerator -> GPU\n",
    "# Colab gives you access to up to 12 free continuous hours of a fairly recent GPU.\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "frOGRjz0mL_5"
   },
   "source": [
    "# Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hp-KevLKmLLP"
   },
   "outputs": [],
   "source": [
    "# Let's download the MNIST dataset, available at https://www.openml.org/d/554\n",
    "# You can edit the argument data_home to the directory of your choice.\n",
    "# The dataset will be downloaded there; the default directory is ~/scikit_learn_data/\n",
    "X, y = datasets.fetch_openml('mnist_784', version=1, return_X_y=True, data_home=None, as_frame=False)\n",
    "nb_of_samples, nb_of_features = X.shape\n",
    "# X = 70k samples, 28*28 features; y = 70k samples, 1 label (string)\n",
    "\n",
    "# Shuffle the dataset\n",
    "X, y = utils.shuffle(X, y)\n",
    "\n",
    "# Convert the labels (string) to integers for convenience\n",
    "y = np.array(y, dtype=int)\n",
    "nb_of_ouputs = np.max(y) + 1\n",
    "\n",
    "# We'll normalize our input data in the range [0, 1[.\n",
    "X = X / pow(2, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgamMat1mXvu"
   },
   "source": [
    "# Conversion en décharges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "moU3ZUh8mSFG",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# And convert the data to a spike train using TTFS encoding\n",
    "dt = 1*units.ms\n",
    "duration_per_image = 100*units.ms\n",
    "absolute_duration = int(duration_per_image / dt)\n",
    "\n",
    "time_of_spike = (1 - X) * absolute_duration  # The brighter the pixel, the earlier the spike\n",
    "time_of_spike[X < .25] = 0  # \"Remove\" the spikes associated with darker pixels, which presumably carry less information\n",
    "\n",
    "sample_id, neuron_idx = np.nonzero(time_of_spike)\n",
    "\n",
    "# We use a sparse COO array to store the spikes for memory requirements\n",
    "# You can use the spike_train variable as if it were a tensor of shape (nb_of_samples, nb_of_features, absolute_duration)\n",
    "spike_train = COO((sample_id, neuron_idx, time_of_spike[sample_id, neuron_idx].astype(int)),\n",
    "                  np.ones_like(sample_id), shape=(nb_of_samples, nb_of_features, absolute_duration))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IAxIwqtumyda"
   },
   "source": [
    "# Split entrainement/test/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_of_samples = 70000\n",
      "\n",
      "train_indices = [    0     1     2 ... 55997 55998 55999]\n",
      "train_indices.shape = (56000,)\n",
      "\n",
      "test_indices = [56000 56001 56002 ... 62997 62998 62999]\n",
      "test_indices.shape = (7000,)\n",
      "\n",
      "validation_indices = [63000 63001 63002 ... 69997 69998 69999]\n",
      "validation_indices.shape = (7000,)\n",
      "\n",
      "total = 70000\n"
     ]
    }
   ],
   "source": [
    "# Nombre total d'échantillons\n",
    "print(\"nb_of_samples =\", nb_of_samples)\n",
    "\n",
    "# 80% pour l'entraînement\n",
    "nb_of_train_samples = int(nb_of_samples * 0.80)\n",
    "\n",
    "# 10% pour test\n",
    "nb_of_test_samples = int(nb_of_samples * 0.10)\n",
    "\n",
    "# 10% pour validation\n",
    "nb_of_validation_samples = nb_of_samples - nb_of_train_samples - nb_of_test_samples\n",
    "\n",
    "# Création des indices\n",
    "train_indices = np.arange(nb_of_train_samples)\n",
    "test_indices = np.arange(nb_of_train_samples, nb_of_train_samples + nb_of_test_samples)\n",
    "validation_indices = np.arange(nb_of_train_samples + nb_of_test_samples, nb_of_samples)\n",
    "\n",
    "print(\"\\ntrain_indices =\", train_indices)\n",
    "print(\"train_indices.shape =\", train_indices.shape)\n",
    "\n",
    "print(\"\\ntest_indices =\", test_indices)\n",
    "print(\"test_indices.shape =\", test_indices.shape)\n",
    "\n",
    "print(\"\\nvalidation_indices =\", validation_indices)\n",
    "print(\"validation_indices.shape =\", validation_indices.shape)\n",
    "\n",
    "total_samples = train_indices.shape[0] + test_indices.shape[0] + validation_indices.shape[0]\n",
    "print(\"\\ntotal =\", total_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZWlfjmhjmdPz"
   },
   "source": [
    "# Création du réseau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wqeJ9wNBm_84"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0166, -0.0201, -0.0915,  ...,  0.1204, -0.0279,  0.1034],\n",
       "        [ 0.0904, -0.0630, -0.0854,  ...,  0.1121, -0.0862, -0.1139],\n",
       "        [ 0.0663, -0.0444,  0.0240,  ...,  0.0991, -0.0835,  0.0579],\n",
       "        ...,\n",
       "        [-0.2037,  0.0690,  0.0162,  ..., -0.0634,  0.0101, -0.0868],\n",
       "        [ 0.0544, -0.1185,  0.1433,  ..., -0.0279, -0.0658,  0.1325],\n",
       "        [ 0.0045,  0.0288,  0.0155,  ..., -0.0239, -0.0366, -0.0218]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a 2 layer network (1 hidden, 1 output)\n",
    "nb_hidden = 128  # Number of hidden neurons\n",
    "\n",
    "w1 = torch.empty((nb_of_features, nb_hidden), device=device, dtype=torch.float, requires_grad=True)\n",
    "torch.nn.init.normal_(w1, mean=0., std=.1)\n",
    "\n",
    "w2 = torch.empty((nb_hidden, nb_of_ouputs), device=device, dtype=torch.float, requires_grad=True)\n",
    "torch.nn.init.normal_(w2, mean=0., std=.1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Différentes fonctions d'activation et leur dérrivées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#out = torch.zeros_like(input)\n",
    "#         out[input > 0] = 1.0 # On génère une décharge quand (potential-threshold) > 0\n",
    "\n",
    "def relu_forward(input):\n",
    "    \"\"\"Propagation avant pour ReLU\"\"\"\n",
    "    out = torch.where(input > 0, torch.ones_like(input), torch.zeros_like(input))\n",
    "    return out\n",
    "\n",
    "def relu_backward(input):\n",
    "    \"\"\"Rétropropagation pour ReLU\"\"\"\n",
    "    grad_input = torch.ones_like(input)\n",
    "    grad_input[input < 0] = 0\n",
    "    return grad_input\n",
    "\n",
    "def leaky_relu_forward(input, alpha=0.01):\n",
    "    \"\"\"Propagation avant pour Leaky ReLU\"\"\"\n",
    "    out = torch.where(input > 0, input, alpha * input)  # Leaky ReLU avec alpha\n",
    "    return out\n",
    "\n",
    "def leaky_relu_backward(input, alpha=0.01):\n",
    "    \"\"\"Rétropropagation pour Leaky ReLU\"\"\"\n",
    "    grad_input = torch.ones_like(input)\n",
    "    grad_input[input < 0] = alpha  # La dérivée du leaky ReLU est alpha pour les valeurs négatives\n",
    "    return grad_input\n",
    "\n",
    "def abs_relu_forward(input):\n",
    "    \"\"\"Propagation avant pour ReLU absolu\"\"\"\n",
    "    out = torch.abs(input)  # ReLU absolu\n",
    "    return out\n",
    "\n",
    "def abs_relu_backward(input):\n",
    "    \"\"\"Rétropropagation pour ReLU absolu\"\"\"\n",
    "    grad_input = torch.ones_like(input)\n",
    "    grad_input[input < 0] = -1  # La dérivée du ReLU absolu est -1 pour les valeurs négatives\n",
    "    return grad_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classe pour la rétropropagation de l'erreur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "rrZ3qeWfnBwj"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class SpikeFunction(torch.autograd.Function):\n",
    "#     \"\"\"\n",
    "#     Cette classe permet de calculer la sortie d'une fonction lors de la propagation avant\n",
    "#     et de personnaliser la dérivée lors de la rétropropagation de l'erreur.\n",
    "#     \"\"\"\n",
    "\n",
    "#     @staticmethod\n",
    "#     def forward(ctx, input, activation_type='relu', alpha=0.01):\n",
    "#         \"\"\"\n",
    "#         Dans la passe avant, nous recevons un tenseur contenant l'entrée (potential-threshold).\n",
    "#         Nous appliquons la fonction d'activation choisie.\n",
    "#         \"\"\"\n",
    "#         ctx.save_for_backward(input)\n",
    "#         ctx.activation_type = activation_type\n",
    "#         ctx.alpha = alpha\n",
    "        \n",
    "#         # Choisir la fonction d'activation en fonction du type spécifié\n",
    "#         if activation_type == 'relu':\n",
    "#             out = relu_forward(input)\n",
    "#         elif activation_type == 'leaky_relu':\n",
    "#             out = leaky_relu_forward(input, alpha)\n",
    "#         elif activation_type == 'abs_relu':\n",
    "#             out = abs_relu_forward(input)\n",
    "#         else:\n",
    "#             raise ValueError(f\"Activation type '{activation_type}' is not supported.\")\n",
    "        \n",
    "#         return out\n",
    "\n",
    "#     @staticmethod\n",
    "#     def backward(ctx, grad_output):\n",
    "#         \"\"\"\n",
    "#         Dans la passe arrière, nous recevons un tenseur contenant le gradient de l'erreur par rapport à la sortie.\n",
    "#         Nous calculons le gradient de l'erreur par rapport à l'entrée en fonction de l'activation choisie.\n",
    "#         \"\"\"\n",
    "#         input, = ctx.saved_tensors\n",
    "#         activation_type = ctx.activation_type\n",
    "#         alpha = ctx.alpha\n",
    "        \n",
    "#         # Choisir la fonction d'activation en fonction du type spécifié\n",
    "#         if activation_type == 'relu':\n",
    "#             grad_input = relu_backward(input)\n",
    "#         elif activation_type == 'leaky_relu':\n",
    "#             grad_input = leaky_relu_backward(input, alpha)\n",
    "#         elif activation_type == 'abs_relu':\n",
    "#             grad_input = abs_relu_backward(input)\n",
    "#         else:\n",
    "#             raise ValueError(f\"Activation type '{activation_type}' is not supported.\")\n",
    "        \n",
    "#         # Retourner le gradient de l'entrée\n",
    "#         return grad_output * grad_input\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Cette class permet de calculer la sortie d'une fonction lors de la propagation avant et de personaliser la derivée lors de la retropropagation de l'erreur.\n",
    "Voir cet exemple pour plus de détails : https://pytorch.org/tutorials/beginner/examples_autograd/two_layer_net_custom_function.html\n",
    "\"\"\"\n",
    "class SpikeFunction(torch.autograd.Function):\n",
    "    \"\"\"\n",
    "    Dans la passe avant, nous recevons un tenseur contenant l'entrée (potential-threshold).\n",
    "    Nous appliquons la fonction Heaviside et renvoyons un tenseur contenant la sortie.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        ctx.save_for_backward(input)\n",
    "        out = torch.zeros_like(input)\n",
    "        out[input > 0] = 1.0 # On génère une décharge quand (potential-threshold) > 0\n",
    "        return out\n",
    "\n",
    "    \"\"\"\n",
    "    Dans la passe arrière, nous recevons un tenseur contenant le gradient de l'erreur par rapport à la sortie.\n",
    "    Nous calculons le gradient de l'erreur par rapport à l'entrée en utilisant la dérivée de la fonction ReLu.\n",
    "    \"\"\"\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        input, = ctx.saved_tensors\n",
    "        grad_relu = torch.ones_like(input) # La dérivée de la fonction ReLU\n",
    "        grad_relu[input < 0] = 0          # La dérivée de la fonction ReLU\n",
    "        return grad_output.clone()*grad_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xAXZCMNsnIri"
   },
   "outputs": [],
   "source": [
    "def run_spiking_layer(input_spike_train, layer_weights, tau_v=20*units.ms, tau_i=5*units.ms, v_threshold=1.0):\n",
    "    \"\"\"Here we implement a current-LIF dynamic in PyTorch\"\"\"\n",
    "\n",
    "    # First, we multiply the input spike train by the weights of the current layer to get the current that will be added\n",
    "    # We can calculate this beforehand because the weights are constant in the forward pass (no plasticity)\n",
    "    input_current = torch.einsum(\"abc,bd->adc\", (input_spike_train, layer_weights))  # Equivalent to a matrix multiplication for tensors of dim > 2 using Einstein's Notation\n",
    "\n",
    "    recorded_spikes = []  # Array of the output spikes at each time t\n",
    "    membrane_potential_at_t = torch.zeros((input_spike_train.shape[0], layer_weights.shape[-1]), device=device, dtype=torch.float)\n",
    "    membrane_current_at_t = torch.zeros((input_spike_train.shape[0], layer_weights.shape[-1]), device=device, dtype=torch.float)\n",
    "\n",
    "    for t in range(absolute_duration):  # For every timestep\n",
    "        # Apply the leak\n",
    "        membrane_potential_at_t = float(np.exp(-dt/tau_v))*membrane_potential_at_t # Using tau_v with euler or exact method\n",
    "        membrane_current_at_t = float(np.exp(-dt/tau_i))*membrane_current_at_t # Using tau_i with euler or exact method\n",
    "\n",
    "        # Select the input current at time t\n",
    "        input_at_t = input_current[:, :, t]\n",
    "\n",
    "        # Integrate the input current\n",
    "        membrane_current_at_t += input_at_t\n",
    "\n",
    "        # Integrate the input to the membrane potential\n",
    "        membrane_potential_at_t += membrane_current_at_t\n",
    "\n",
    "        # Apply the non-differentiable function\n",
    "        #recorded_spikes_at_t = SpikeFunction.apply(membrane_potential_at_t - v_threshold)\n",
    "        recorded_spikes_at_t = SpikeFunction.apply(membrane_potential_at_t - v_threshold)\n",
    "        #, activation_type='relu'\n",
    "        #activation_type='leaky_relu', alpha=0.01\n",
    "        #activation_type='abs_relu'\n",
    "\n",
    "        \n",
    "        recorded_spikes.append(recorded_spikes_at_t)\n",
    "\n",
    "        # Reset the spiked neurons\n",
    "        membrane_potential_at_t[membrane_potential_at_t > v_threshold] = 0\n",
    "\n",
    "    recorded_spikes = torch.stack(recorded_spikes, dim=2) # Stack over time axis (Array -> Tensor)\n",
    "    return recorded_spikes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xNEAhvjlnVqF"
   },
   "source": [
    "# Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "dPyehEEZzc4x"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 -- loss : 329.8574\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 0.3328050673007965, Second = 0.6578252911567688, Last = -0.36469849944114685\n",
      "\n",
      "Epoch 2 -- loss : 292.1398\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 0.5268695950508118, Second = 1.106713891029358, Last = -0.32680296897888184\n",
      "\n",
      "Epoch 3 -- loss : 286.1379\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 0.7428810000419617, Second = 1.4544264078140259, Last = -0.053780850023031235\n",
      "\n",
      "Epoch 4 -- loss : 284.1332\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 0.9212635159492493, Second = 1.725002646446228, Last = 0.4456058144569397\n",
      "\n",
      "Epoch 5 -- loss : 282.5805\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.0635664463043213, Second = 1.9738435745239258, Last = 1.0515027046203613\n",
      "\n",
      "Epoch 6 -- loss : 281.5027\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.1782759428024292, Second = 2.19453763961792, Last = 1.6422052383422852\n",
      "\n",
      "Epoch 7 -- loss : 280.5748\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.269734501838684, Second = 2.376833438873291, Last = 2.1541688442230225\n",
      "\n",
      "Epoch 8 -- loss : 279.7964\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.34452486038208, Second = 2.508909225463867, Last = 2.580355167388916\n",
      "\n",
      "Epoch 9 -- loss : 279.0960\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.4102321863174438, Second = 2.59169864654541, Last = 2.9492950439453125\n",
      "\n",
      "Epoch 10 -- loss : 278.5660\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.460290789604187, Second = 2.6302671432495117, Last = 3.261096477508545\n",
      "\n",
      "Epoch 11 -- loss : 277.7857\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.5077495574951172, Second = 2.648318290710449, Last = 3.5318026542663574\n",
      "\n",
      "Epoch 12 -- loss : 277.2965\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.5526090860366821, Second = 2.6582326889038086, Last = 3.769237518310547\n",
      "\n",
      "Epoch 13 -- loss : 276.7152\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.595729947090149, Second = 2.6586856842041016, Last = 3.9615659713745117\n",
      "\n",
      "Epoch 14 -- loss : 276.2672\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.6342335939407349, Second = 2.6453182697296143, Last = 4.1159563064575195\n",
      "\n",
      "Epoch 15 -- loss : 275.7238\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.6778109073638916, Second = 2.63344407081604, Last = 4.245261192321777\n",
      "\n",
      "Epoch 16 -- loss : 275.2275\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.7199947834014893, Second = 2.6169533729553223, Last = 4.347570419311523\n",
      "\n",
      "Epoch 17 -- loss : 274.8864\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.761824607849121, Second = 2.5982613563537598, Last = 4.428068161010742\n",
      "\n",
      "Epoch 18 -- loss : 274.6137\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.7990925312042236, Second = 2.579955577850342, Last = 4.491466045379639\n",
      "\n",
      "Epoch 19 -- loss : 274.2834\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.8313385248184204, Second = 2.560070753097534, Last = 4.540905475616455\n",
      "\n",
      "Epoch 20 -- loss : 274.0559\n",
      "Weight evolution - w1: First = -0.11258398741483688, Second = -0.08833757787942886, Last = -0.02453634701669216\n",
      "Weight evolution - w2: First = 1.8595272302627563, Second = 2.5401382446289062, Last = 4.577398300170898\n"
     ]
    }
   ],
   "source": [
    "# Set-up training\n",
    "nb_of_epochs = 20\n",
    "batch_size = 256  # The backpropagation is done after every batch, but a batch here is also used for memory requirements\n",
    "number_of_batches = len(train_indices) // batch_size\n",
    "\n",
    "params = [w1, w2]  # Trainable parameters\n",
    "optimizer = torch.optim.Adam(params, lr=0.01, amsgrad=True)\n",
    "loss_fn = torch.nn.MSELoss(reduction='mean')\n",
    "\n",
    "# Initialisation des listes pour stocker les poids\n",
    "w1_history = []\n",
    "w2_history = []\n",
    "\n",
    "for e in range(nb_of_epochs):\n",
    "    epoch_loss = 0\n",
    "    for batch in np.array_split(train_indices, number_of_batches):\n",
    "        # Select batch and convert to tensors\n",
    "        batch_spike_train = torch.FloatTensor(spike_train[batch].todense()).to(device)\n",
    "        batch_labels = torch.LongTensor(y[batch, np.newaxis]).to(device)\n",
    "\n",
    "        # Here we create a target spike count (10 spikes for wrong label, 100 spikes for true label) in a one-hot fashion\n",
    "        # This approach is seen in Shrestha & Orchard (2018) https://arxiv.org/pdf/1810.08646.pdf\n",
    "        # Code available at https://github.com/bamsumit/slayerPytorch\n",
    "        min_spike_count = 10 * torch.ones((batch.shape[0], 10), device=device, dtype=torch.float)\n",
    "        target_output = min_spike_count.scatter_(1, batch_labels, 100.0)\n",
    "\n",
    "        # Forward propagation\n",
    "        layer_1_spikes = run_spiking_layer(batch_spike_train, w1)\n",
    "        layer_2_spikes = run_spiking_layer(layer_1_spikes, w2)\n",
    "        network_output = torch.sum(layer_2_spikes, 2)  # Count the spikes over time axis\n",
    "        loss = loss_fn(network_output, target_output)\n",
    "\n",
    "        # Backward propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(\"\\nEpoch %i -- loss : %.4f\" %(e+1, epoch_loss / number_of_batches))\n",
    "    # Affichage des 1er, 2e et dernier poids de w1 et w2\n",
    "    print(f\"Weight evolution - w1: First = {w1.detach().cpu().numpy()[0][0]}, Second = {w1.detach().cpu().numpy()[1][0]}, Last = {w1.detach().cpu().numpy()[-1][0]}\")\n",
    "    print(f\"Weight evolution - w2: First = {w2.detach().cpu().numpy()[0][0]}, Second = {w2.detach().cpu().numpy()[1][0]}, Last = {w2.detach().cpu().numpy()[-1][0]}\")\n",
    "    w1_history.append(w1.detach().cpu().numpy())  \n",
    "    w2_history.append(w2.detach().cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:red;\">Validation</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the accuracy of the model\n",
    "correct_label_count = 0\n",
    "\n",
    "# We only need to batchify the test set for memory requirements\n",
    "for batch in np.array_split(validation_indices,  len(validation_indices) // batch_size):\n",
    "    validation_spike_train = torch.FloatTensor(spike_train[batch].todense()).to(device)\n",
    "\n",
    "    # Same forward propagation as before\n",
    "    layer_1_spikes = run_spiking_layer(validation_spike_train, w1)\n",
    "    layer_2_spikes = run_spiking_layer(layer_1_spikes, w2)\n",
    "    network_output = torch.sum(layer_2_spikes, 2)  # Count the spikes over time axis\n",
    "\n",
    "    # Do the prediction by selecting the output neuron with the most number of spikes\n",
    "    _, am = torch.max(network_output, 1)\n",
    "    correct_label_count += np.sum(am.detach().cpu().numpy() == y[batch])\n",
    "\n",
    "print(\"Model accuracy on test set: %.3f\" % (correct_label_count / len(test_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0j4qQrgVnihY"
   },
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NgQyFnPetmxQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy on test set: 0.866\n"
     ]
    }
   ],
   "source": [
    "# Test the accuracy of the model\n",
    "correct_label_count = 0\n",
    "\n",
    "# We only need to batchify the test set for memory requirements\n",
    "for batch in np.array_split(test_indices,  len(test_indices) // batch_size):\n",
    "    test_spike_train = torch.FloatTensor(spike_train[batch].todense()).to(device)\n",
    "\n",
    "    # Same forward propagation as before\n",
    "    layer_1_spikes = run_spiking_layer(test_spike_train, w1)\n",
    "    layer_2_spikes = run_spiking_layer(layer_1_spikes, w2)\n",
    "    network_output = torch.sum(layer_2_spikes, 2)  # Count the spikes over time axis\n",
    "\n",
    "    # Do the prediction by selecting the output neuron with the most number of spikes\n",
    "    _, am = torch.max(network_output, 1)\n",
    "    correct_label_count += np.sum(am.detach().cpu().numpy() == y[batch])\n",
    "\n",
    "print(\"Model accuracy on test set: %.3f\" % (correct_label_count / len(test_indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Évolution des poids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mÉpoque\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mylabel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPoids\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\Users\\cllam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\pyplot.py:3588\u001b[0m, in \u001b[0;36mlegend\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   3586\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mlegend)\n\u001b[0;32m   3587\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlegend\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Legend:\n\u001b[1;32m-> 3588\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cllam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\axes\\_axes.py:342\u001b[0m, in \u001b[0;36mAxes.legend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03mPlace a legend on the Axes.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    339\u001b[0m \u001b[38;5;124;03m.. plot:: gallery/text_labels_and_annotations/legend.py\u001b[39;00m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    341\u001b[0m handles, labels, kwargs \u001b[38;5;241m=\u001b[39m mlegend\u001b[38;5;241m.\u001b[39m_parse_legend_args([\u001b[38;5;28mself\u001b[39m], \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m--> 342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegend_ \u001b[38;5;241m=\u001b[39m \u001b[43mmlegend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLegend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegend_\u001b[38;5;241m.\u001b[39m_remove_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_remove_legend\n\u001b[0;32m    344\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlegend_\n",
      "File \u001b[1;32mc:\\Users\\cllam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\legend.py:563\u001b[0m, in \u001b[0;36mLegend.__init__\u001b[1;34m(self, parent, handles, labels, loc, numpoints, markerscale, markerfirst, reverse, scatterpoints, scatteryoffsets, prop, fontsize, labelcolor, borderpad, labelspacing, handlelength, handleheight, handletextpad, borderaxespad, columnspacing, ncols, mode, fancybox, shadow, title, title_fontsize, framealpha, edgecolor, facecolor, bbox_to_anchor, bbox_transform, frameon, handler_map, title_fontproperties, alignment, ncol, draggable)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_alignment \u001b[38;5;241m=\u001b[39m alignment\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# init with null renderer\u001b[39;00m\n\u001b[1;32m--> 563\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_legend_box\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarkerfirst\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;66;03m# Set legend location\u001b[39;00m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_loc(loc)\n",
      "File \u001b[1;32mc:\\Users\\cllam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\legend.py:898\u001b[0m, in \u001b[0;36mLegend._init_legend_box\u001b[1;34m(self, handles, labels, markerfirst)\u001b[0m\n\u001b[0;32m    896\u001b[0m     handle_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    897\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 898\u001b[0m     textbox \u001b[38;5;241m=\u001b[39m \u001b[43mTextArea\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultilinebaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    899\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtextprops\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    900\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mverticalalignment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbaseline\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    901\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mhorizontalalignment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    902\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mfontproperties\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    903\u001b[0m     handlebox \u001b[38;5;241m=\u001b[39m DrawingArea(width\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandlelength \u001b[38;5;241m*\u001b[39m fontsize,\n\u001b[0;32m    904\u001b[0m                             height\u001b[38;5;241m=\u001b[39mheight,\n\u001b[0;32m    905\u001b[0m                             xdescent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.\u001b[39m, ydescent\u001b[38;5;241m=\u001b[39mdescent)\n\u001b[0;32m    907\u001b[0m     text_list\u001b[38;5;241m.\u001b[39mappend(textbox\u001b[38;5;241m.\u001b[39m_text)\n",
      "File \u001b[1;32mc:\\Users\\cllam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\offsetbox.py:703\u001b[0m, in \u001b[0;36mTextArea.__init__\u001b[1;34m(self, s, textprops, multilinebaseline)\u001b[0m\n\u001b[0;32m    701\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m textprops \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    702\u001b[0m     textprops \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m--> 703\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text \u001b[38;5;241m=\u001b[39m \u001b[43mmtext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mText\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtextprops\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_children \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text]\n",
      "File \u001b[1;32mc:\\Users\\cllam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\text.py:136\u001b[0m, in \u001b[0;36mText.__init__\u001b[1;34m(self, x, y, text, color, verticalalignment, horizontalalignment, multialignment, fontproperties, rotation, linespacing, rotation_mode, usetex, wrap, transform_rotates_text, parse_math, antialiased, **kwargs)\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    105\u001b[0m              x\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m    106\u001b[0m              color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,           \u001b[38;5;66;03m# defaults to rc params\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    119\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    120\u001b[0m              ):\n\u001b[0;32m    121\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;124;03m    Create a `.Text` instance at *x*, *y* with string *text*.\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;124;03m    %(Text:kwdoc)s\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 136\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    137\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_y \u001b[38;5;241m=\u001b[39m x, y\n\u001b[0;32m    138\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\cllam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\artist.py:201\u001b[0m, in \u001b[0;36mArtist.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Normally, artist classes need to be queried for mouseover info if and\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# only if they override get_cursor_data.\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mouseover \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mget_cursor_data \u001b[38;5;241m!=\u001b[39m Artist\u001b[38;5;241m.\u001b[39mget_cursor_data\n\u001b[1;32m--> 201\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_callbacks \u001b[38;5;241m=\u001b[39m \u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCallbackRegistry\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpchanged\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\cllam\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\matplotlib\\cbook.py:188\u001b[0m, in \u001b[0;36mCallbackRegistry.__init__\u001b[1;34m(self, exception_handler, signals)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_func_cid_map \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    187\u001b[0m \u001b[38;5;66;03m# A hidden variable that marks cids that need to be pickled.\u001b[39;00m\n\u001b[1;32m--> 188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pickled_cids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convertir les listes en un format utilisable pour matplotlib\n",
    "w1_history = np.array(w1_history)\n",
    "w2_history = np.array(w2_history)\n",
    "\n",
    "# Sélectionner 1/100 des indices pour alléger les graphiques\n",
    "step = max(1, len(w1_history) // 100)\n",
    "\n",
    "# Tracer l'évolution des poids de la couche 1 (w1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(w1_history.shape[1]):  # itère sur chaque neurone de la couche 1\n",
    "    plt.plot(w1_history[::step, i], label=f\"Poids neurone {i+1}\")\n",
    "plt.title(\"Évolution des poids de w1 au fil du temps\")\n",
    "plt.xlabel(\"Époque\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Tracer l'évolution des poids de la couche 2 (w2)\n",
    "plt.figure(figsize=(10, 5))\n",
    "for i in range(w2_history.shape[1]):  # itère sur chaque neurone de la couche 2\n",
    "    plt.plot(w2_history[::step, i], label=f\"Poids neurone {i+1}\")\n",
    "plt.title(\"Évolution des poids de w2 au fil du temps\")\n",
    "plt.xlabel(\"Époque\")\n",
    "plt.ylabel(\"Poids\")\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
